\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{geometry}

% Algorithm packages
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{algorithmicx}

% Additional customization for algorithms
\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\algorithmicoutput{\textbf{Output:}}
\algnewcommand\Input{\item[\algorithmicinput]}
\algnewcommand\Output{\item[\algorithmicoutput]}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue
}

% Page setup
\geometry{margin=1in}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

% Custom commands
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}

\title{Implementation of the Lagrangian Relaxation Algorithm for Network Revenue Management}
\author{Hongzhang ``Steve'' Shao}
\date{May 18, 2025}

\begin{document}

\maketitle

\vspace{0.5cm}



% ------------------------------------------------------------------------------------------------
% ABSTRACT
% - Who is the customer? What is their need? Why do they need this solution?
% - What does this product do? How does it benefit the customer?
% - How is success measured for this product? When will it be considered successful?
% ------------------------------------------------------------------------------------------------

% \noindent
% This repository provides a public implementation of the Lagrangian Relaxation Algorithm for network revenue management, originally developed by Prof. Huseyin Topaloglu (2009). 
% Researchers in operations research often use this algorithm and its test dataset as benchmarks, but no open implementation has been available until now. 
% This code allows researchers to test, compare, and build upon the algorithm easily. 
% I have tested our implementation on all instances in Prof. Topaloglu's dataset, and the results match those reported in his paper. \\

% \noindent
% I developed this project as part of my research with Prof. Baris Ata on solving NRM problems with deep learning-based numerical methods. 
% I hope this implementation will help others support reproducible research and further work in network revenue management.

% \vspace{0.5cm}



% ------------------------------------------------------------------------------------------------
% INTRODUCTION
% ------------------------------------------------------------------------------------------------

% \section{Introduction}

% \vspace{0.5cm}


% ------------------------------------------------------------------------------------------------
% SECTION
% ------------------------------------------------------------------------------------------------

\section{The NRM Problem}

Consider a \textbf{network revenue management problem} with:
\begin{itemize}[itemsep=0pt,parsep=0pt]
\item[-] A set of resources (flight legs) $\mathcal{L}$, each with capacity $c_i$ for $i\in \mathcal{L}$. 
\item[-] A set of products (itineraries) $\mathcal{J}$, each with revenue $f_j$ for $j\in \mathcal{J}$. 
    \begin{itemize}[itemsep=0pt,parsep=0pt]
    \item Each purchase of product $j$ consumes $a_{ij}$ units of capacity from resource $i$ for each $i$. 
    \end{itemize}
\item[-] Discrete time horizon $\mathcal{T}=\{1,\ldots,\tau\}$. 
\end{itemize}

\noindent
In each period $t$:
\begin{itemize}[itemsep=0pt,parsep=0pt]
\item[-] \textbf{At most one customer arrives}
\item[-] The customer requests product $j$ with probability $p_{jt}$
\item[-] $\sum_{j\in \mathcal{J}} p_{jt} \le 1$
\end{itemize}

\noindent
Note that, by adding a dummy itinerary $\psi$ with 
\begin{align*}
    f_{\psi} &= 0 \\
    a_{i\psi} &= 0 & \forall i \in \mathcal{L} \\
    p_{\psi t} &= 1 - \sum_{j\in \mathcal{J}} p_{jt} & \forall t \in \mathcal{T}
\end{align*}
It can be assumed that in each period $t$:
\begin{itemize}[itemsep=0pt,parsep=0pt]
\item[-] One customer arrives
\item[-] The customer requests product $j$ with probability $p_{jt}$
\item[-] $\sum_{j\in \mathcal{J}} p_{jt} = 1$
\end{itemize}

\noindent
Let $x_{it}$ be the remaining capacity of resource $i$ at the start of period $t$. 
Let $x_t = \bigl(x_{1t}, x_{2t}, \dots, x_{|\mathcal L|,\,t}\bigr)$ be the state vector. 
Let
\begin{align*}
    C &= \max_{\,i\in\mathcal L}\;c_i \\
    \mathcal{C} &= \{0, 1, \ldots, C\} 
\end{align*}
and let $\mathcal{C}^{|\mathcal{L}|}$ be the state space.

\vspace{0.5cm}



\newpage

% ------------------------------------------------------------------------------------------------
% SECTION
% ------------------------------------------------------------------------------------------------

\section{The LR Algorithm}

\noindent
\textbf{Dynamic Programming Formulation}:
\begin{itemize}[itemsep=0pt,parsep=0pt]
\item[-] Let $u_{jt}\in\{0,1\}$ indicate whether to accept (1) or reject (0) a request for product $j$.
\item[-] Let $V_t(x_t)$ be the maximum expected revenue from period $t$ to $\tau$ given capacities $x_t$:
    \begin{align*}
        V_t(x_t) = \max_{u_t \in \mathcal{U}(x_t)} 
            \left\{ \sum_{j\in \mathcal{J}} p_{jt} 
            \left\{ 
                f_j u_{jt} + 
                V_{t+1} \left(x_t - u_{jt}\sum_{i\in \mathcal{L}}a_{ij}e_i\right) 
            \right\} \right\} 
        \tag{DP1}
    \end{align*}
    where
    \begin{align*}
        \mathcal{U}(x_t) = \left\{ 
            u_{t} \in \{0,1\}^{|\mathcal{J}|} : 
            a_{ij} u_{jt} \le x_{it} \ \ 
            \forall i \in \mathcal{L}, \ j \in \mathcal{J}
        \right\} 
    \end{align*}
    and $e_i$ is the unit vector with a 1 in the $i$-th position and 0 elsewhere.
\end{itemize}

\vspace{0.5cm}

\noindent
\textbf{Equivalent Dynamic Program}:
\begin{itemize}[itemsep=0pt,parsep=0pt]
\item[-] Let $y_{ijt}\in\{0,1\}$ indicate whether to accept (1) or reject (0) \textbf{resource} $i$ when a \textbf{request for product} $j$ arrives (e.g., it is allowed to partially accept some flight legs when an itinerary uses multiple legs).
\item[-] Let $\phi$ be a \textbf{fictitious resource} with infinite capacity. 
\item[-] Let $y_t = \{y_{ijt} : i \in \mathcal{L} \cup \{\phi\}, \ j \in \mathcal{J}\}$.
\item[-] Then, $V_t(x_t)$ can be computed as:
    \begin{align*}
        V_t(x_t) &= \max_{y_t \in \mathcal{Y}(x_t)}
            \left\{ \sum_{j\in \mathcal{J}} p_{jt} 
            \left\{ 
                f_j y_{\phi jt} + 
                V_{t+1} \left(x_t - \sum_{i\in \mathcal{L}}y_{ijt}a_{ij}e_i\right) 
            \right\} \right\}
        \tag{DP2} \\
        & \text{subject to} \quad y_{ijt} = y_{\phi jt} \quad \forall i \in \mathcal{L}, \ j \in \mathcal{J}
    \end{align*}
    where
    \begin{align*}
        \mathcal{Y}_{it}(x_t) &= \left\{ 
            y_{it} \in \{0,1\}^{|\mathcal{J}|} : 
            a_{ij} y_{ijt} \leq x_{it} \ \ 
            \forall j \in \mathcal{J} 
        \right\} \quad i \in \mathcal{L} \\
        \mathcal{Y}_{\phi t}(x_t) &= \left\{ 
            y_{\phi t} \in \{0,1\}^{|\mathcal{J}|} 
        \right\} \\
        \mathcal{Y}(x_t) &= \mathcal{Y}_{\phi t}(x_t) \prod_{i \in \mathcal{L}} \mathcal{Y}_{it}(x_t) \quad \text{(Cartesian product)}
    \end{align*}
\end{itemize}

\vspace{0.5cm}

\noindent
\textbf{Lagrangian Relaxation}:
\begin{itemize}[itemsep=0pt,parsep=0pt]
\item[-] Let $\lambda = \{\lambda_{ijt} : i \in \mathcal{L}, \ j \in \mathcal{J}, \ t \in \mathcal{T}\}$ denote the Lagrangian multiplier. 
\item[-] The Lagrangian relaxation $V^{\lambda}_t(x_t)$ is defined as:
    {\small
    \begin{align*}
        V^{\lambda}_t(x_t) &= \max_{y_t \in \mathcal{Y}(x_t)} 
            \left\{ \sum_{j\in \mathcal{J}} p_{jt} 
            \left[ 
                f_j y_{\phi jt} +
                \sum_{i \in \mathcal{L}} \lambda_{ijt} (y_{ijt} - y_{\phi jt}) + 
                V^{\lambda}_{t+1} \left(x_t - \sum_{i\in \mathcal{L}}y_{ijt}a_{ij}e_i\right) 
            \right] \right\}
            \tag{LR} 
    \end{align*}
    }%
\end{itemize}

\vspace{0.5cm}



\newpage

\noindent
\textbf{Lagrangian Relaxation Algorithm}:
\begin{itemize}
\item[-] \textbf{Goal}: 
    The Lagrangian relaxation algorithm aims to find an optimal multiplier $\lambda^{*}$ that solves
    \begin{align*}
        \min_{\lambda} V^{\lambda}_{1}(c_{1}) 
        \end{align*}
    As shown in \cite{topaloglu2009using},
    \begin{align*}
        V_t(x_t) \leq V^{\lambda}_t(x_t) \quad \forall x_t \in \mathcal{C}^{|\mathcal{L}|}, \ t \in \mathcal{T}
    \end{align*}
    Therefore, $V^{\lambda^{*}}_{1}(c_{1})$ provides a tight bound to $V_{1}(c_{1})$.
\item[-] \textbf{Solving $V^{\lambda}_{1}(c_{1})$ for a given $\lambda$}: 
    It has been shown in \cite{topaloglu2009using} that $V^{\lambda}_{1}(c_{1})$ can be solved by concentrating on one resource at a time. 
    Specifically, if \(\{\vartheta^\lambda_{it}(x_{it}): x_{it} \in \mathcal{C}, t \in \mathcal{T}\}\) is a solution to the optimality equation
    \begin{align*}
        \vartheta^\lambda_{it}(x_{it}) 
        = \max_{y_{it} \in \mathcal{Y}_{it}(x_{it})} 
        \left\{ 
            \sum_{j \in \mathcal{J}} p_{jt} 
            \left[ 
                \lambda_{ijt} y_{ijt} 
                + \vartheta^\lambda_{i, t+1}(x_{it} - a_{ij} y_{ijt}) 
            \right] 
        \right\}
        \tag{SDP}
    \end{align*}
    for all \(i \in \mathcal{L}\), then
    \begin{align}
        V^\lambda_t(x_t) 
        = \sum_{t' = t}^\tau \sum_{j \in \mathcal{J}} p_{jt'} 
            \left[ f_j - \sum_{i \in \mathcal{L}} \lambda_{ijt'} \right]^+ 
        + \sum_{i \in \mathcal{L}} \vartheta^\lambda_{it}(x_{it}),
        \label{eq:lagrangian_relaxation_algorithm}
    \end{align}
    where $[z]^+ = \max\{z, 0\}$.
\item[-] \textbf{Minimizing $V^{\lambda}_{1}(c_{1})$ over $\lambda$}: 
    It has also been shown in \cite{topaloglu2009using} that the Lagrangian relaxation $V^{\lambda}_{1}(c_{1})$ is convex in $\lambda$. 
    Thus, the optimal multiplier $\lambda^*$ can be found by using classical subgradient methods.
\end{itemize}

\vspace{0.5cm}

\noindent
\textbf{Control Policy}:
\begin{itemize}
\item[-] The control policy is to accept a request for product $j$ at time $t$ if and only if:
    \begin{align*}
        f_j \geq \sum_{i \in \mathcal{L}} \sum_{r = 1}^{a_{ij}} \left[ \vartheta^{\lambda^{*}}_{i,t+1}(x_{it} - r + 1) - \vartheta^{\lambda^{*}}_{i,t+1}(x_{it} - r) \right]
    \end{align*}
    That is, a product is accepted if its revenue exceeds the opportunity cost of consumed resources. 
    Specifically, the term $\vartheta^{\lambda^{*}}_{i,t+1}(x_{it}) - \vartheta^{\lambda^{*}}_{i,t+1}(x_{it} - 1)$ represents the bid price of resource $i$ at time $t$.
\end{itemize}

\vspace{0.5cm}



\newpage

% ------------------------------------------------------------------------------------------------
% SECTION
% ------------------------------------------------------------------------------------------------

\section{The subgradient of $V_1^\lambda(\mathbf{c}_1)$}

\noindent
Computing the subgradient is important for updating $\lambda_{ijt}$ when minimizing $V^{\lambda}_{1}(c_{1})$.
However, \cite{topaloglu2009using} does not explicitly provide the subgradient of $V^{\lambda}_{1}(c_{1})$.
In this section, we show how to compute the subgradient of $V^{\lambda}_{1}(c_{1})$ with respect to a specific Lagrange multiplier $\lambda_{ijt}$.

\vspace{0.5cm}

\noindent
\textbf{Single-Resource Value Function and Optimal Policy:}
Recall that the value function $\vartheta^\lambda_{it}(x_{it})$ for resource $i$ with capacity $x_{it}$ at time $t$ is given by the Bellman equation:
\begin{align*}
\vartheta^\lambda_{it}(x_{it}) = \max_{y_{ijt} \in \{0,1\}} \left\{ \sum_{j \in \mathcal{J}} p_{jt} \left[ \lambda_{ijt} y_{ijt} + \vartheta^\lambda_{i, t+1}(x_{it} - a_{ij} y_{ijt}) \right] \right\}
\end{align*}
Let $y^{*\lambda}_{ijt}(x_{it})$ be the optimal decision for product $j$ given capacity $x_{it}$. Then,
\begin{align*}
\vartheta^\lambda_{it}(x_{it}) = \sum_{j \in \mathcal{J}} p_{jt} \left[ \lambda_{ijt} y^{*\lambda}_{ijt}(x_{it}) + \vartheta^\lambda_{i, t+1}(x_{it} - a_{ij} y^{*\lambda}_{ijt}(x_{it})) \right]
\end{align*}
with terminal condition $\vartheta^\lambda_{i, \tau+1}(\cdot) = 0$.
Thus, the value function $\vartheta^\lambda_{i1}(c_i)$ can be written as the expected sum of $\lambda$-weighted accepted products:
\begin{align*}
\vartheta^\lambda_{i1}(c_i) = \mathbb{E} \left[ \sum_{t'=1}^{\tau} \sum_{j \in \mathcal{J}} p_{jt'} \lambda_{ijt'} y^{*\lambda}_{ijt'}(X_{it'}) \mid X_{i1} = c_i \right]
\end{align*}
where $X_{it'}$ is the random capacity at time $t'$.

\vspace{0.5cm}

\noindent
\textbf{Capacity State Probability $\mu_{it}(x)$:}
To see the effect of $\lambda_{ijt}$ on $\vartheta^\lambda_{i1}(c_i)$, define $\mu_{it}(x)$ as the probability that resource $i$ has capacity $x$ at time $t$, starting from $c_i$ at $t=1$ and following the optimal policy $y^{*\lambda}$. This probability mass function is computed recursively:
\begin{itemize}
    \item \textbf{Base case ($t=1$):} $\mu_{i1}(x) = \mathbb{I}\{x = c_i\}$.
    \item \textbf{Recursive step (for $s=1, \ldots, \tau-1$):}
    \begin{align*}
    \mu_{i,s+1}(x') = \sum_{x=0}^{c_{i}} \mu_{is}(x) \sum_{j \in \mathcal{J}} p_{js} \mathbb{I}\left\{x' = x - a_{ij}y^{*\lambda}_{ijs}(x)\right\}
    \end{align*}
\end{itemize}

\vspace{0.5cm}

\noindent
\textbf{The subgradient of $\vartheta^\lambda_{i1}(c_i)$ with respect to $\lambda_{ijt}$:}
As we can see, the change in $\vartheta^\lambda_{i1}(c_i)$ due to $\lambda_{ijt}$ is the sum of local effects at time $t$, weighted by the probability $\mu_{it}(x_{it})$ of being in state $x_{it}$:
\begin{align*}
\frac{\partial \vartheta^\lambda_{i1}(c_i)}{\partial \lambda_{ijt}} = \sum_{x_{it}=0}^{c_{i}} \mu_{it}(x_{it}) \left( p_{jt} y^{*\lambda}_{ijt}(x_{it}) \right) = p_{jt} \sum_{x_{it}=0}^{c_{i}} \mu_{it}(x_{it}) y^{*\lambda}_{ijt}(x_{it})
\end{align*}
Intuitively, the sum $\sum_{x_{it}=0}^{c_{i}} \mu_{it}(x_{it}) y^{*\lambda}_{ijt}(x_{it})$ is the expected optimal decision for product $j$ at time $t$, given initial capacity $c_i$.

\vspace{0.5cm}

\noindent
\textbf{The subgradient of $V^{\lambda}_{1}(c_{1})$ with respect to $\lambda_{ijt}$:}
Using \eqref{eq:lagrangian_relaxation_algorithm}, we have: 
\begin{align*}
    \frac{\partial V^{\lambda}_{1}(c_{1})}{\partial \lambda_{ijt}} 
    &= \frac{\partial \vartheta^\lambda_{i1}(c_{i})}{\partial \lambda_{ijt}} 
    - p_{jt} \,\mathbf{1}\left\{f_j - \sum_{k \in \mathcal{L}} \lambda_{kjt} \ge 0\right\} 
\end{align*}



\newpage

% ------------------------------------------------------------------------------------------------
% SECTION
% ------------------------------------------------------------------------------------------------

\section{Implementation}

\noindent
\textbf{Note:} \cite{topaloglu2009using} did not provide any specific implementation details or the choice of algorithms. Thus, I need to do my own implementation. What follows are my own implementation steps.

\vspace{0.5cm}



% ------------------------------------------------------------------------------------------------
\subsection{Subroutine: Solving the Single-Resource Dynamic Program}

\noindent
We solve the single-resource optimality equation using tabular backward induction:

\begin{algorithm}[H]
\caption{Subroutine: Tabular Backward Induction for Single-Resource Dynamic Program}
\label{alg:solve_sdp}
\begin{algorithmic}[1]
\Require Resource $i$, capacities $\mathcal{C}$, time periods $\mathcal{T}$, probabilities $p_{jt}$, consumption $a_{ij}$, multipliers $\lambda_{ijt}$
\Ensure Value functions $\vartheta^\lambda_{it}(x_{it})$ and optimal decisions $y^*_{ijt}(x_{it})$
\State Initialize $\vartheta^\lambda_{i,\tau+1}(x_{i,\tau+1}) \gets 0$ for all $x_{i,\tau+1} \in \mathcal{C}$ \Comment{Terminal condition}
\For{$t = \tau$ \textbf{down to} $1$} \Comment{Backward recursion}
    \For{$x_{it} = 0$ \textbf{to} $C$} \Comment{For each capacity level}
        \State $\vartheta^\lambda_{it}(x_{it}) \gets 0$
        \State $y^*_{ijt}(x_{it}) \gets 0$ for all $j \in \mathcal{J}$ \Comment{Initialize decision variables}
        \For{$j \in \mathcal{J}$} \Comment{For each product}
            \If{$a_{ij} \leq x_{it}$} \Comment{Check if capacity is sufficient}
                \State $v_0 \gets \vartheta^\lambda_{i,t+1}(x_{it})$ \Comment{Value if reject}
                \State $v_1 \gets \lambda_{ijt} + \vartheta^\lambda_{i,t+1}(x_{it} - a_{ij})$ \Comment{Value if accept}
                \If{$v_1 > v_0$}
                    \State $y^*_{ijt}(x_{it}) \gets 1$ \Comment{Accept product $j$ at time $t$ with capacity $x_{it}$}
                \EndIf
            \EndIf
        \EndFor
        \State $\displaystyle \vartheta^\lambda_{it}(x_{it}) \gets \sum_{j\in\mathcal{J}} p_{jt}\Bigl[ \lambda_{ijt}\,y^*_{ijt}(x_{it}) + \vartheta^\lambda_{i,t+1}\!\bigl(x_{it}-a_{ij}y^*_{ijt}(x_{it})\bigr) \Bigr]$
    \EndFor
\EndFor
\State \Return $\{\vartheta^\lambda_{it}(x_{it}): x_{it} \in \mathcal{C}, t \in \mathcal{T}\}$ and $\{y^*_{ijt}(x_{it}): j \in \mathcal{J}, x_{it} \in \mathcal{C}, t \in \mathcal{T}\}$
\end{algorithmic}
\end{algorithm}

\vspace{0.5cm}



\newpage

% ------------------------------------------------------------------------------------------------
\subsection{Subroutine: Computing State Probabilities}

\noindent
This subroutine is executed for each resource $i \in \mathcal{L}$. 
It computes the state occupancy probabilities $\mu_{is}(x)$ for resource $i$ at each time $s \in \mathcal{T}$ and capacity level $x \in \mathcal{C}$. 
These probabilities indicate the likelihood of resource $i$ having $x$ units of capacity at the beginning of period $s$, given an initial capacity $c_{i,1}$ at $s=1$ and following the optimal single-resource policies $y^{*\lambda}_{ijs}(x)$ derived from Algorithm~\ref{alg:solve_sdp}.

\begin{algorithm}[H]
\caption{Compute State Probabilities $\mu_{is}(x)$ for Resource $i$}
\label{alg:compute_mu}
\begin{algorithmic}[1]
\Require Resource $i$, initial capacity $c_{i,1}$, maximum capacity $C$, time periods $\mathcal{T}$, product set $\mathcal{J}$, arrival probabilities $p_{js}$, consumption $a_{ij}$, optimal policies $y^{*\lambda}_{ijs}(x)$
\Ensure State probabilities $\mu_{is}(x)$ for $s \in \mathcal{T}, x \in \{0, \ldots, C\}$

\State Initialize array $\mu_{i \cdot (\cdot)} : (\mathcal{T} \times \mathcal{C}) \to \R$ with all entries $0.0$.
\State $\mu_{i1}(c_{i,1}) \gets 1.0$ \Comment{At $s=1$, capacity is $c_{i,1}$ with prob. 1}

\For{$s = 1$ \textbf{to} $\tau-1$} \Comment{Forward in time}
    \For{$x_{curr} = 0$ \textbf{to} $C$} \Comment{For each capacity at $s$}
        \If{$\mu_{is}(x_{curr}) > 10^{-9}$} \Comment{If $x_{curr}$ is reachable}
            \For{$j \in \mathcal{J}$} \Comment{For each product $j$}
                \State $y^*_{curr} \gets y^{*\lambda}_{i,j,s}(x_{curr})$ \Comment{Optimal decision at $(i,s,x_{curr})$}
                \State $x_{next} \gets x_{curr} - a_{i,j} \cdot y^*_{curr}$
                \If{$x_{next} < 0$} \Comment{Negative capacity should not actually occur!}
                    \State $x_{next} \gets 0$ 
                \EndIf
                \State $\mu_{i,s+1}(x_{next}) \gets \mu_{i,s+1}(x_{next}) + \mu_{is}(x_{curr}) \cdot p_{j,s}$
            \EndFor
        \EndIf
    \EndFor
\EndFor

\State \Return $\mu$ array (containing $\mu_{is}(x)$)
\end{algorithmic}
\end{algorithm}

\vspace{0.5cm}



\newpage

% ------------------------------------------------------------------------------------------------
\subsection{Subroutine: Computing $\vartheta$-Subgradient}

\noindent
This subroutine uses the state probabilities and the optimal policies to calculate the subgradient of the single-resource total expected $\lambda$-weighted value $\vartheta^\lambda_{i1}(c_{i,1})$ with respect to each relevant Lagrange multiplier $\lambda_{ijs}$.

\begin{algorithm}[H]
\caption{Compute $\vartheta$-Subgradient $G_{ijs}$ for Resource $i$}
\label{alg:compute_subgrad_vartheta}
\begin{algorithmic}[1]
\Require State probabilities $\mu_{is}(x)$, optimal policies $y^{*\lambda}_{ijs}(x)$, arrival probabilities $p_{js}$, product set $\mathcal{J}$, time periods $\mathcal{T}$, maximum capacity $C$
\Ensure Subgradients $G_{ijs} = \frac{\partial \vartheta^\lambda_{i1}(c_{i,1})}{\partial \lambda_{ijs}}$ for $j \in \mathcal{J}, s \in \mathcal{T}$

\State Initialize array $G_{i \cdot \cdot} : (\mathcal{J} \times \mathcal{T}) \to \R$ with all entries set to $0.0$.

\For{$s = 1$ \textbf{to} $\tau$} \Comment{For each time period $s$}
    \For{$j \in \mathcal{J}$} \Comment{For each product $j$}
        \State $\text{expected\_y\_star}_{ijs} \gets 0$
        \For{$x = 0$ \textbf{to} $C$} \Comment{For each capacity level $x$ at time $s$}
            \If{$\mu_{is}(x) > 10^{-9}$} \Comment{If state $(i,s,x)$ is reachable}
                \State $\text{expected\_y\_star}_{ijs} \gets \text{expected\_y\_star}_{ijs} + \mu_{is}(x) \cdot y^{*\lambda}_{i,j,s}(x)$
            \EndIf
        \EndFor
        \State $G_{i,j,s} \gets p_{j,s} \cdot \text{expected\_y\_star}_{ijs}$
    \EndFor
\EndFor

\State \Return $G$ array (containing $G_{ijs}$)
\end{algorithmic}
\end{algorithm}



\newpage

% ------------------------------------------------------------------------------------------------
\subsection{Final Subgradient Optimization}

\noindent
Note that as a Lagrangian multiplier, $\lambda_{ijt} \ge 0$. 
Thus, here we use a projected subgradient descent algorithm to optimize $\lambda$.
\begin{algorithm}[H]
\caption{Projected Subgradient Descent for Lagrangian Multiplier Optimization}
\begin{algorithmic}[1]
\Require Initial multipliers $\lambda^0$, step size $\alpha_0$, tolerance $\epsilon$, maximum iterations $K$
\Ensure Optimized multipliers $\lambda^*$
\State $k \gets 0$
\State $V_{\text{prev}} \gets \infty$
\While{$k < K$}
    \State Compute $V^{\lambda^k}_{1}(c_{1})$
    \If{$|V^{\lambda^k}_{1}(c_{1}) - V_{\text{prev}}| < \epsilon$}
        \State \textbf{break}
    \EndIf
    \State $V_{\text{prev}} \gets V^{\lambda^k}_{1}(c_{1})$
    \State Compute subgradient $g^k$ of $V^{\lambda^k}_{1}(c_{1})$ with respect to $\lambda$. 
    \State $\alpha_k \gets \frac{\alpha_0}{\sqrt{k+1}}$
    \State $\lambda^{k+1} \gets \max\{0, \lambda^k - \alpha_k g^k\}$ \Comment{Project onto feasible set}
    \State $k \gets k + 1$
\EndWhile
\State \Return $\lambda^k$
\end{algorithmic}
\end{algorithm}

\vspace{0.5cm}


% \noindent
% Once the optimal Lagrangian multipliers $\lambda^*$ are obtained (e.g., using Algorithm 4), the control policy based on bid prices can be defined. To evaluate the performance of this policy, we can estimate the total expected revenue by simulating customer arrivals and decisions over the time horizon. The following algorithm describes this Monte Carlo simulation process.

% \vspace{0.5cm}

% \noindent
% \textbf{Note:} Due to the curse of dimensionality, the exact dynamic programming approach is computationally feasible only for small networks. For larger instances, Monte Carlo simulation can approximate the expected revenue by sampling customer arrivals and applying the bid price policy iteratively.


\newpage

% ------------------------------------------------------------------------------------------------
\subsection{Algorithm: Computing Total Expected Revenue using Bid Prices}

\noindent
After obtaining optimal Lagrangian multipliers $\lambda^*$ (e.g., via Algorithm 4), we define a bid price control policy. To evaluate this policy, we estimate total expected revenue through Monte Carlo simulation of customer arrivals and decisions. The algorithm below details this process.

\vspace{0.5cm}

\begin{algorithm}[H]
\caption{Estimate Total Expected Revenue using Bid Price Policy (Monte Carlo Simulation)}
\label{alg:monte_carlo_revenue}
\begin{algorithmic}[1]
\Require Precomputed value functions $\vartheta^{\lambda^*}_{i,t'}(x)$, initial capacities $c$, product set $\mathcal{J}$ (incl. dummy $\psi$), revenues $f_j$, resource consumptions $a_{ij}$, arrival probabilities $p_{jt}$, time horizon $\mathcal{T} = \{1, \ldots, \tau\}$, number of simulations $N_{sim}$
\Ensure Estimated total expected revenue $E[R]$

\State Initialize $total\_rev \gets 0.0$

\For{$s = 1$ \textbf{to} $N_{sim}$} \Comment{For each simulation run $s$}
    \State $run\_rev \gets 0.0$
    \State $cap \gets \text{copy of } c$ \Comment{Reset capacities for this run}
    \For{$t = 1$ \textbf{to} $\tau$} \Comment{For each time period $t$}
        \State Sample product $j$ using probabilities $\{p_{jt}\}_{j \in \mathcal{J}}$ for time $t$.
        
        \If{$f_{j} > 0$} \Comment{Process non-dummy products (dummy $\psi$ has $f_\psi=0$)}
            \State $opp\_cost \gets 0.0$
            \State $enough\_cap \gets \text{true}$
            
            \Comment{Assess $j$: check capacity and calculate opportunity cost}
            \For{$i \in \mathcal{L}$ such that $a_{ij} > 0$} \Comment{For each resource $i$ consumed by $j$}
                \If{$cap[i] < a_{ij}$}
                    \State $enough\_cap \gets \text{false}$
                    \State \textbf{break} \Comment{Insufficient capacity for $j$ on resource $i$}
                \EndIf
                \For{$r = 1$ \textbf{to} $a_{ij}$} \Comment{Sum bid prices for each unit of $i$ consumed}
                    \State $bp \gets \vartheta^{\lambda^*}_{i,t+1}(cap[i] - r + 1) - \vartheta^{\lambda^*}_{i,t+1}(cap[i] - r)$
                    \State $opp\_cost \gets opp\_cost + bp$
                \EndFor
            \EndFor
            
            \If{$enough\_cap \text{ and } f_{j} \ge opp\_cost$} \Comment{Accept $j$}
                \State $run\_rev \gets run\_rev + f_{j}$
                \For{$i \in \mathcal{L}$ such that $a_{ij} > 0$} \Comment{Update consumed capacities}
                    \State $cap[i] \gets cap[i] - a_{ij}$
                \EndFor
            \EndIf
        \EndIf
        \Comment{Capacities $cap$ are now updated for period $t+1$}
    \EndFor \Comment{End of time horizon $\mathcal{T}$ for run $s$}
    \State $total\_rev \gets total\_rev + run\_rev$
\EndFor \Comment{End of $N_{sim}$ simulation runs}

\State $E[R] \gets total\_rev / N_{sim}$
\State \Return $E[R]$
\end{algorithmic}
\end{algorithm}


% ------------------------------------------------------------------------------------------------
% 
% ------------------------------------------------------------------------------------------------

\newpage

\section{Numerical Results}

The exact results depend on the tuning of algorithm parameters, such as step length and other settings. 
Below is a comparison of our final results with those reported in \cite{topaloglu2009using}.


\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{l|l|l|l|l|l}
\hline
\textbf{Problem} & \textbf{Upper Bound} & \textbf{Upper Bound} & \textbf{Mean Revenue} & \textbf{Mean Revenue} & \textbf{Std (Our Impl} \\
 & \textbf{(Huseyin)} & \textbf{(Our Impl.)} & \textbf{(Huseyin)} & \textbf{(Our Impl.)} & \textbf{1000 Samples)} \\
\hline
rm\_200\_4\_1.0\_4.0 & 20,439 & \textcolor{green}{20,436} & 20,018 & \textcolor{green}{20,049} & 31.31 \\
rm\_200\_4\_1.0\_8.0 & 33,305 & \textcolor{green}{33,261} & 32,226 & \textcolor{green}{32,821} & 62.70 \\
rm\_200\_4\_1.2\_4.0 & 18,938 & \textcolor{green}{18,885} & 18,374 & \textcolor{green}{18,510} & 28.49 \\
rm\_200\_4\_1.2\_8.0 & 31,737 & \textcolor{green}{31,651} & 30,852 & \textcolor{green}{31,271} & 64.73 \\
rm\_200\_4\_1.6\_4.0 & 16,600 & \textcolor{green}{16,541} & 15,981 & \textcolor{green}{16,186} & 27.72 \\
rm\_200\_4\_1.6\_8.0 & 29,413 & \textcolor{green}{29,247} & 28,381 & \textcolor{green}{28,978} & 63.80 \\
rm\_200\_5\_1.0\_4.0 & 21,298 & \textcolor{green}{21,296} & 21,181 & \textcolor{red}{20,973} & 34.79 \\
rm\_200\_5\_1.0\_8.0 & 34,393 & \textcolor{green}{34,377} & 34,271 & \textcolor{red}{34,068} & 69.42 \\
rm\_200\_5\_1.2\_4.0 & 20,184 & \textcolor{green}{20,112} & 19,818 & \textcolor{red}{19,677} & 33.06 \\
rm\_200\_5\_1.2\_8.0 & 33,165 & \textcolor{green}{33,051} & 32,766 & \textcolor{red}{32,620} & 68.80 \\
rm\_200\_5\_1.6\_4.0 & 17,704 & \textcolor{green}{17,654} & 17,318 & \textcolor{red}{17,218} & 30.93 \\
rm\_200\_5\_1.6\_8.0 & 30,594 & \textcolor{green}{30,492} & 30,107 & \textcolor{red}{29,980} & 66.84 \\
rm\_200\_6\_1.0\_4.0 & 21,128 & \textcolor{green}{21,113} & 20,709 & \textcolor{green}{20,729} & 33.13 \\
rm\_200\_6\_1.0\_8.0 & 34,178 & \textcolor{green}{34,102} & 33,466 & \textcolor{green}{33,664} & 66.86 \\
rm\_200\_6\_1.2\_4.0 & 19,649 & \textcolor{green}{19,636} & 19,156 & \textcolor{green}{19,165} & 31.25 \\
rm\_200\_6\_1.2\_8.0 & 32,566 & \textcolor{green}{32,520} & 31,808 & \textcolor{green}{31,993} & 67.36 \\
rm\_200\_6\_1.6\_4.0 & 17,304 & \textcolor{green}{17,256} & 16,269 & \textcolor{green}{16,837} & 30.08 \\
rm\_200\_6\_1.6\_8.0 & 30,170 & \textcolor{green}{30,061} & 29,320 & \textcolor{green}{29,599} & 65.70 \\
rm\_200\_8\_1.0\_4.0 & 18,975 & \textcolor{green}{18,778} & 18,217 & \textcolor{green}{18,268} & 31.10 \\
rm\_200\_8\_1.0\_8.0 & 30,490 & \textcolor{green}{30,275} & 29,453 & \textcolor{green}{29,716} & 66.44 \\
rm\_200\_8\_1.2\_4.0 & 17,472 & \textcolor{red}{17,501} & 16,941 & \textcolor{red}{16,915} & 29.44 \\
rm\_200\_8\_1.2\_8.0 & 28,908 & \textcolor{green}{28,889} & 28,130 & \textcolor{green}{28,236} & 61.56 \\
rm\_200\_8\_1.6\_4.0 & 15,295 & \textcolor{red}{15,297} & 14,720 & \textcolor{green}{14,764} & 27.34 \\
rm\_200\_8\_1.6\_8.0 & 26,661 & \textcolor{green}{26,555} & 25,701 & \textcolor{green}{25,988} & 63.75 \\
rm\_600\_4\_1.0\_4.0 & 30,995 & \textcolor{green}{30,994} & 30,640 & \textcolor{red}{30,575} & 49.25 \\
rm\_600\_4\_1.0\_8.0 & 50,444 & \textcolor{green}{50,406} & 49,862 & \textcolor{green}{49,872} & 107.31 \\
rm\_600\_4\_1.2\_4.0 & 28,668 & \textcolor{green}{28,615} & 28,145 & \textcolor{green}{28,167} & 44.65 \\
rm\_600\_4\_1.2\_8.0 & 48,054 & \textcolor{green}{47,947} & 47,162 & \textcolor{green}{47,541} & 101.67 \\
rm\_600\_4\_1.6\_4.0 & 25,148 & \textcolor{green}{25,084} & 24,540 & \textcolor{green}{24,596} & 43.50 \\
rm\_600\_4\_1.6\_8.0 & 44,555 & \textcolor{green}{44,357} & 43,547 & \textcolor{green}{44,003} & 102.95 \\
rm\_600\_5\_1.0\_4.0 & 32,254 & \textcolor{red}{32,272} & 32,112 & \textcolor{red}{31,775} & 56.33 \\
rm\_600\_5\_1.0\_8.0 & 52,071 & \textcolor{green}{52,056} & 51,275 & \textcolor{green}{51,668} & 118.57 \\
rm\_600\_5\_1.2\_4.0 & 30,004 & \textcolor{red}{30,552} & 30,308 & \textcolor{red}{30,100} & 51.57 \\
rm\_600\_5\_1.2\_8.0 & 50,282 & \textcolor{green}{50,162} & 49,899 & \textcolor{red}{49,629} & 114.59 \\
rm\_600\_5\_1.6\_4.0 & 26,936 & \textcolor{green}{26,880} & 26,605 & \textcolor{red}{26,441} & 44.95 \\
rm\_600\_5\_1.6\_8.0 & 46,497 & \textcolor{green}{46,355} & 46,070 & \textcolor{red}{45,858} & 107.20 \\
rm\_600\_6\_1.0\_4.0 & 25,541 & \textcolor{red}{25,559} & 25,310 & \textcolor{red}{25,044} & 47.32 \\
rm\_600\_6\_1.0\_8.0 & 41,412 & \textcolor{green}{41,262} & 40,849 & \textcolor{red}{40,753} & 102.27 \\
rm\_600\_6\_1.2\_4.0 & 23,687 & \textcolor{red}{23,708} & 23,306 & \textcolor{red}{23,191} & 42.77 \\
rm\_600\_6\_1.2\_8.0 & 39,307 & \textcolor{green}{39,270} & 38,704 & \textcolor{green}{38,799} & 100.42 \\
rm\_600\_6\_1.6\_4.0 & 20,817 & \textcolor{green}{20,788} & 20,273 & \textcolor{red}{20,229} & 41.46 \\
rm\_600\_6\_1.6\_8.0 & 36,381 & \textcolor{green}{36,261} & 35,631 & \textcolor{green}{35,867} & 101.19 \\
rm\_600\_8\_1.0\_4.0 & 22,960 & \textcolor{green}{22,798} & 22,269 & \textcolor{red}{22,206} & 44.93 \\
rm\_600\_8\_1.0\_8.0 & 36,933 & \textcolor{green}{36,718} & 36,046 & \textcolor{green}{36,071} & 95.73 \\
rm\_600\_8\_1.2\_4.0 & 21,102 & \textcolor{red}{21,172} & 20,633 & \textcolor{red}{20,431} & 39.54 \\
rm\_600\_8\_1.2\_8.0 & 34,831 & \textcolor{red}{34,939} & 34,277 & \textcolor{red}{34,168} & 88.63 \\
rm\_600\_8\_1.6\_4.0 & 18,500 & \textcolor{red}{18,553} & 17,830 & \textcolor{green}{17,888} & 35.95 \\
rm\_600\_8\_1.6\_8.0 & 32,247 & \textcolor{green}{32,180} & 31,317 & \textcolor{green}{31,411} & 90.19 \\
\hline
\end{tabular}
\caption{Comparison of bounds and revenues. Green: our value is better; Red: our value is worse.}
\end{table}


% ------------------------------------------------------------------------------------------------
% LITERATURE REVIEW
% ------------------------------------------------------------------------------------------------

\newpage

\section{Resources}

This project is based on \cite{topaloglu2009using}.
Both the paper and its dataset are publicly available on Prof. Huseyin Topaloglu's \underline{\href{https://people.orie.cornell.edu/huseyin}{website}}. 
You can access the paper directly \underline{\href{https://people.orie.cornell.edu/huseyin/publications/revenue_man.pdf}{here}}.
The dataset can be downloaded from \underline{\href{https://people.orie.cornell.edu/huseyin/research/rm_datasets/rm_datasets.html}{this page}}.

\vspace{0.5cm}



% ------------------------------------------------------------------------------------------------
% SECTION
% ------------------------------------------------------------------------------------------------

\bibliographystyle{apalike}
\bibliography{references}

\end{document}
